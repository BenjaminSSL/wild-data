{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "165a65cb-098c-46e3-b08e-0fd939271fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4075/3388578945.py:11: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\"out.csv\", chunksize=chunksize, dtype={\"column_name\": str}):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Large dataset --> split into chunks of 1 200 000 lines per csv.\n",
    "chunksize = 1_200_000\n",
    "i = 0\n",
    "output_dir = \"csv_splits\"\n",
    "\n",
    "# The split csvs are saved into the defined output directory\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for chunk in pd.read_csv(\"out.csv\", chunksize=chunksize, dtype={\"column_name\": str}):\n",
    "    chunk.to_csv(os.path.join(output_dir, f\"split_{i}.csv\"), index=False)\n",
    "    i += 1\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72a533a0-6cc6-4c64-a914-01016ca64dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def process_file(path, output_path):\n",
    "    \n",
    "    df = pd.read_csv(path, quotechar='\"', low_memory=False)\n",
    "    \n",
    "    df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "\n",
    "    df[\"licencePlate\"] = (\n",
    "        df[\"licencePlate\"]\n",
    "        .astype(str)\n",
    "        .str.lower()\n",
    "        .str.replace(\" \", \"\", regex=False)\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "    # Ensure proper ordering\n",
    "    df[\"file_datetime\"] = pd.to_datetime(df[\"file_datetime\"], errors=\"coerce\")\n",
    "    df = df.sort_values(['licencePlate', 'file_datetime']).reset_index(drop=True)\n",
    "\n",
    "    df[\"zipCode\"] = (df[\"zipCode\"].astype(str).str.extract(r'(\\d{4})').astype(float).fillna(-1).astype(int))\n",
    "\n",
    "    # Thresholds\n",
    "    thr = 1e-3\n",
    "    time_thr = pd.Timedelta(minutes=10)\n",
    "\n",
    "    lat  = df['lat'].to_numpy()\n",
    "    lon  = df['lon'].to_numpy()\n",
    "    plate= df['licencePlate'].to_numpy()\n",
    "    time = df['file_datetime'].to_numpy()\n",
    "\n",
    "    # Plate change\n",
    "    plate_change = np.r_[True, plate[1:] != plate[:-1]]\n",
    "\n",
    "    # Location change\n",
    "    move_change = np.r_[False,\n",
    "        (np.abs(lat[1:] - lat[:-1]) > thr) |\n",
    "        (np.abs(lon[1:] - lon[:-1]) > thr)\n",
    "    ]\n",
    "\n",
    "    # Time change\n",
    "    time_diff = np.diff(time, prepend=time[0])\n",
    "    time_change = time_diff > time_thr\n",
    "\n",
    "    # Any boundary event\n",
    "    boundary = plate_change | move_change | time_change\n",
    "    b_idx = np.flatnonzero(boundary)\n",
    "\n",
    "    # Closing segments\n",
    "    end_idx   = np.r_[b_idx[1:] - 1, len(df) - 1]\n",
    "    start_idx = b_idx[:len(end_idx)]\n",
    "\n",
    "    # Build output\n",
    "    grouped = pd.DataFrame({\n",
    "        \"licencePlate\": df.loc[start_idx, \"licencePlate\"].to_numpy(),\n",
    "        \"start_time\":   df.loc[start_idx, \"file_datetime\"].to_numpy(),\n",
    "        \"end_time\":     df.loc[end_idx,   \"file_datetime\"].to_numpy(),\n",
    "        \"start_lat\":    df.loc[start_idx, \"lat\"].to_numpy(),\n",
    "        \"start_lon\":    df.loc[start_idx, \"lon\"].to_numpy(),\n",
    "        \"end_lat\":      df.loc[end_idx,   \"lat\"].to_numpy(),\n",
    "        \"end_lon\":      df.loc[end_idx,   \"lon\"].to_numpy(),\n",
    "        \"travel_time\": np.round(\n",
    "            (df.loc[end_idx, \"file_datetime\"].to_numpy() -\n",
    "             df.loc[start_idx, \"file_datetime\"].to_numpy()) /\n",
    "             np.timedelta64(1, \"m\")\n",
    "        ).astype(int),\n",
    "        \"vehicleTypeId\": df.loc[start_idx, \"vehicleTypeId\"].astype(str).to_numpy(),\n",
    "        \"zipCode\": df.loc[start_idx, \"zipCode\"].to_numpy()\n",
    "    })\n",
    "\n",
    "    # car-type mapping\n",
    "    car_types = {\n",
    "        \"1\": {\"model\":\"Renault Zoe\",\"type\":\"car\"},\n",
    "        \"2\": {\"model\":\"Renault Zoe\",\"type\":\"car\"},\n",
    "        \"6\": {\"model\":\"unknown\",\"type\":\"van\"},\n",
    "        \"9\":  {\"model\":\"Renault Zoe\",\"type\":\"car\"},\n",
    "        \"10\": {\"model\":\"Renault Zoe\",\"type\":\"car\"},\n",
    "        \"14\": {\"model\":\"Renault Zoe\",\"type\":\"car\"},\n",
    "        \"25\": {\"model\":\"unknown\",\"type\":\"van\"},\n",
    "        \"26\": {\"model\":\"Renault Zoe\",\"type\":\"car\"},\n",
    "        \"31\": {\"model\":\"unknown\",\"type\":\"van\"},\n",
    "        \"32\": {\"model\":\"SAIC Motor MAXUS E-Deliver 3\",\"type\":\"van\"},\n",
    "        \"34\": {\"model\":\"Renault Zoe\",\"type\":\"car\"},\n",
    "        \"35\": {\"model\":\"Renault Zoe\",\"type\":\"car\"},\n",
    "        \"57\": {\"model\":\"Renault Zoe\",\"type\":\"car\"},\n",
    "        \"64\": {\"model\":\"Renault Zoe\",\"type\":\"car\"},\n",
    "        \"74\": {\"model\":\"unknown\",\"type\":\"van\"},\n",
    "        \"76\": {\"model\":\"Mercedes eVito\",\"type\":\"van\"},\n",
    "        \"77\": {\"model\":\"Renault Zoe\",\"type\":\"car\"},\n",
    "        \"79\": {\"model\":\"Peugeot e-Partner\",\"type\":\"van\"},\n",
    "        \"86\": {\"model\":\"Renault Zoe\",\"type\":\"car\"},\n",
    "        \"91\": {\"model\":\"Renault Zoe\",\"type\":\"car\"},\n",
    "        \"94\": {\"model\":\"Renault Zoe\",\"type\":\"car\"},\n",
    "        \"95\": {\"model\":\"Renault Kangoo\",\"type\":\"van\"},\n",
    "        \"96\": {\"model\":\"Renault Zoe\",\"type\":\"car\"},\n",
    "        \"97\": {\"model\":\"Renault Zoe\",\"type\":\"car\"},\n",
    "        \"99\": {\"model\":\"Renault Zoe\",\"type\":\"car\"},\n",
    "        \"102\": {\"model\":\"Renault Megane\",\"type\":\"car\"},\n",
    "        \"103\": {\"model\":\"Opel Vivaro Electric\",\"type\":\"van\"},\n",
    "        \"105\": {\"model\":\"Renault Zoe\",\"type\":\"car\"},\n",
    "        \"106\": {\"model\":\"Renault Zoe\",\"type\":\"car\"},\n",
    "        \"107\": {\"model\":\"Renault Zoe\",\"type\":\"car\"},\n",
    "        \"109\": {\"model\":\"Renault Trafic E-Tech\",\"type\":\"van\"},\n",
    "        \"111\": {\"model\":\"Ford E-Transit\",\"type\":\"van\"}\n",
    "    }\n",
    "\n",
    "    df_car_types = pd.DataFrame(car_types).T\n",
    "    df_car_types.index.name = \"vehicleTypeId\"\n",
    "    df_car_types.reset_index(inplace=True)\n",
    "    \n",
    "    grouped[\"vehicleTypeId\"] = grouped[\"vehicleTypeId\"].astype(str)\n",
    "    grouped = grouped.merge(df_car_types, on=\"vehicleTypeId\", how=\"left\")\n",
    "\n",
    "\n",
    "    # Filling NaN with 'unknown'\n",
    "    grouped[\"model\"] = grouped[\"model\"].fillna(\"unknown\")\n",
    "    grouped[\"type\"] = grouped[\"type\"].fillna(\"unknown\")\n",
    "\n",
    "\n",
    "    # Postal-code mapping\n",
    "    post_codes = {\n",
    "        1: {\"name\": \"Bronshoj\",         \"zip_from\": 2700, \"zip_to\": 2700, \"setting\": 2700},\n",
    "        2: {\"name\": \"Kobenhavn K\",      \"zip_from\": 1050, \"zip_to\": 1473, \"setting\": 1050},\n",
    "        3: {\"name\": \"Kobenhavn N\",      \"zip_from\": 2200, \"zip_to\": 2200, \"setting\": 2200},\n",
    "        4: {\"name\": \"Kobenhavn NV\",     \"zip_from\": 2400, \"zip_to\": 2400, \"setting\": 2400},\n",
    "        5: {\"name\": \"Kobenhavn O\",      \"zip_from\": 2100, \"zip_to\": 2100, \"setting\": 2100},\n",
    "        6: {\"name\": \"Kobenhavn S\",      \"zip_from\": 2300, \"zip_to\": 2300, \"setting\": 2300},\n",
    "        7: {\"name\": \"Kobenhavn SV\",     \"zip_from\": 2450, \"zip_to\": 2450, \"setting\": 2450},\n",
    "        8: {\"name\": \"Kobenhavn V\",      \"zip_from\": 1550, \"zip_to\": 1799, \"setting\": 1550},\n",
    "        9: {\"name\": \"Nordhavn\",         \"zip_from\": 2150, \"zip_to\": 2150, \"setting\": 2150},\n",
    "        10: {\"name\": \"Valby\",           \"zip_from\": 2500, \"zip_to\": 2500, \"setting\": 2500},\n",
    "        11: {\"name\": \"Vanlose\",         \"zip_from\": 2720, \"zip_to\": 2720, \"setting\": 2720},\n",
    "        12: {\"name\": \"Frederiksberg C\", \"zip_from\": 1800, \"zip_to\": 2000, \"setting\": 2000},\n",
    "    }\n",
    "    df_codes = pd.DataFrame(post_codes).T\n",
    "    df_codes['zip_from'] = df_codes['zip_from'].astype(int)\n",
    "    df_codes['zip_to'] = df_codes['zip_to'].astype(int)\n",
    "    \n",
    "    # Convert zipCode to numeric safely\n",
    "    grouped['zipCode'] = pd.to_numeric(grouped['zipCode'], errors='coerce').fillna(-1).astype(int)\n",
    "\n",
    "    # Interval index for mapping\n",
    "    iv = pd.IntervalIndex.from_arrays(df_codes['zip_from'], df_codes['zip_to'], closed='both')\n",
    "\n",
    "    zips = grouped['zipCode'].to_numpy()\n",
    "    pos = iv.get_indexer(zips)\n",
    "    mask = pos != -1\n",
    "    zip_fixed = zips.copy()\n",
    "    zip_fixed[mask] = df_codes['setting'].to_numpy()[pos[mask]]\n",
    "    grouped['postcode'] = zip_fixed\n",
    "    grouped['zipCodeFixed'] = zip_fixed\n",
    "\n",
    "    grouped[\"end_zipCode\"] = df.loc[end_idx, \"zipCode\"].to_numpy()\n",
    "    grouped[\"end_zipCode\"] = pd.to_numeric(df.loc[end_idx, \"zipCode\"], errors='coerce').fillna(-1).astype(int)\n",
    "\n",
    "    z2 = grouped[\"end_zipCode\"].to_numpy()\n",
    "    pos2 = iv.get_indexer(z2)\n",
    "    mask2 = pos2 != -1\n",
    "    zip_fixed2 = z2.copy()\n",
    "    zip_fixed2[mask2] = df_codes['setting'].to_numpy()[pos2[mask2]]\n",
    "\n",
    "    grouped[\"end_postcode\"] = zip_fixed2\n",
    "\n",
    "    zip_to_name = df_codes.set_index(\"setting\")[\"name\"].to_dict()\n",
    "\n",
    "    valid_zipcodes = set(df_codes[\"setting\"].astype(int))\n",
    "\n",
    "    mask_keep = (\n",
    "        grouped[\"zipCodeFixed\"].isin(valid_zipcodes)\n",
    "        & grouped[\"end_zipCode\"].isin(valid_zipcodes)\n",
    "    )\n",
    "    \n",
    "    grouped = grouped[mask_keep].reset_index(drop=True)\n",
    "\n",
    "\n",
    "    grouped[\"start_area\"] = grouped[\"postcode\"].map(zip_to_name).fillna(\"Unknown\")\n",
    "    grouped[\"end_area\"] = grouped[\"end_postcode\"].map(zip_to_name).fillna(\"Unknown\")\n",
    "\n",
    "    grouped[\"route\"] = grouped[\"start_area\"] + \" â†’ \" + grouped[\"end_area\"]\n",
    "\n",
    "    # Temporal fields\n",
    "    grouped[\"day_of_week\"] = pd.to_datetime(grouped[\"start_time\"]).dt.day_name()\n",
    "    grouped[\"hour_of_day\"] = pd.to_datetime(grouped[\"start_time\"]).dt.hour\n",
    "\n",
    "    grouped = grouped[\n",
    "        ~(\n",
    "            (grouped[\"travel_time\"] == 0) &\n",
    "            (grouped[\"start_lat\"] == grouped[\"end_lat\"]) &\n",
    "            (grouped[\"start_lon\"] == grouped[\"end_lon\"])\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Safe write (overwrite)\n",
    "    temp = output_path + \".tmp\"\n",
    "    grouped.to_csv(temp, index=False)\n",
    "    os.replace(temp, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fe8404a-6bdd-4e81-89e3-9f62b9040b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the process_file function\n",
    "output_dir = \"csv_splits\"\n",
    "\n",
    "input_files = sorted(glob.glob(os.path.join(output_dir, \"split_*.csv\")))\n",
    "\n",
    "for f in input_files:\n",
    "    process_file(f, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb1a9806-0786-4fb6-be51-28b88cdd58b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output written to: transformed_output.csv\n"
     ]
    }
   ],
   "source": [
    "# Gathering the processed split csv into one complete file\n",
    "output_dir = \"csv_splits\"\n",
    "\n",
    "processed_files = sorted(glob.glob(os.path.join(output_dir, \"split_*.csv\")))\n",
    "output_final = \"transformed_output.csv\"\n",
    "\n",
    "dfs = []\n",
    "for f in processed_files:\n",
    "    df = pd.read_csv(\n",
    "        f,\n",
    "        quotechar='\"',\n",
    "        parse_dates=[\"start_time\", \"end_time\"],\n",
    "        low_memory=False\n",
    "    )\n",
    "    dfs.append(df)\n",
    "\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "final_df.to_csv(output_final, index=False)\n",
    "\n",
    "print(\"Final output written to:\", output_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b783b2-ce54-4040-9519-964d69fd4f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd80e722-6966-414a-9b15-3c80aef0ad2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
